{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Copy of Assignment3_2_.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vqxH49KJN6B_"},"source":["import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import cv2\n","from tensorflow.keras.applications.resnet50 import ResNet50\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZx-LTqIN9o4"},"source":["!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QzkYRb-3OLYv"},"source":["!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKNkPBy6N6CF"},"source":["def mapDirectoryToInt():\n","    ID_DICT = {}\n","    PATH = 'tiny-imagenet-200/wnids.txt'\n","    FILEOPEN = open(PATH,'r')\n","    for i, folder in enumerate(FILEOPEN):\n","        ID_DICT[folder.replace('\\n','')]=i\n","    return ID_DICT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6z6PI4CrN6CI"},"source":["def getImage(folderName=None):\n","    DATASET_PATH = 'tiny-imagenet-200/'+folderName+'/'\n","    directories = os.listdir(DATASET_PATH)\n","    ONE_HOT_ENCODED = np.eye(len(directories))\n","    MAP_DIC = mapDirectoryToInt()\n","    TRAIN_IMAGES = []\n","    TRAIN_LABELS = []\n","    CLASS = None\n","    for directory in directories:\n","        path = DATASET_PATH+directory+'/'\n","        files = os.listdir(path)\n","        if files[0].endswith('.txt'):\n","            CLASS = files[0]\n","        else:\n","            CLASS = files[1]\n","        for file in files:\n","            if file.endswith('.txt'):\n","                continue\n","            IMG_FOLDER_PATH = path+file+'/'\n","            IMAGES = os.listdir(IMG_FOLDER_PATH)\n","            for IMAGE in IMAGES:\n","                IMG_PATH = IMG_FOLDER_PATH+IMAGE\n","                img = cv2.imread(IMG_PATH)\n","                if len(img.shape)< 3:\n","                    continue\n","                #img = np.reshape(img,[64,64,3])\n","                TRAIN_IMAGES.append(img)\n","                TRAIN_LABELS.append((np.reshape(ONE_HOT_ENCODED[MAP_DIC[CLASS.replace('_boxes.txt','')]], [200])))\n","    return np.array(TRAIN_IMAGES), np.array(TRAIN_LABELS)\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3heU9a-8N6CJ"},"source":["def loadValidationData(folderName=None):\n","    DATASET_PATH = 'tiny-imagenet-200/'\n","    DATASET_FILE_PATH = 'tiny-imagenet-200/'+folderName+'/val_annotations.txt'\n","    ONE_HOT_ENCODED = np.eye(200)\n","    MAP_DIC = mapDirectoryToInt()\n","    file = open(DATASET_FILE_PATH)\n","    TEST = []\n","    TEST_LABELS = []\n","    for line in file:\n","        image, class_id = line.split('\\t')[:2]\n","        IMG_PATH = DATASET_PATH+folderName+'/images/'+image\n","        img = cv2.imread(IMG_PATH)\n","        if len(img.shape) <3:\n","            continue\n","        TEST.append(img)\n","        TEST_LABELS.append((np.reshape(ONE_HOT_ENCODED[MAP_DIC[class_id]], [200])))\n","    return np.array(TEST), np.array(TEST_LABELS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLAmbdWiN6CK"},"source":["from tensorflow import keras\n","TEST_IMAGES, TEST_LABELS = loadValidationData('val')\n","TEST_IMAGES = keras.applications.resnet50.preprocess_input(TEST_IMAGES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuN-wjl4N6CL"},"source":["print(TEST_IMAGES.shape)\n","print(TEST_LABELS.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5_OkKZvN6CN"},"source":["TRAIN_IMAGES, TRAIN_LABELS = getImage('train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HhECKeFfA6h"},"source":["\n","TRAIN_IMAGES =  keras.applications.resnet50.preprocess_input(TRAIN_IMAGES)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"joBBTjdIN6CP"},"source":["path = 'tiny-imagenet-200/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcRqr05iasNL"},"source":["import tensorflow.keras as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"acez-I0Sayg2"},"source":["input_shape = K.Input(shape=(64,64,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAmtLLauN6CU"},"source":["\n","resModel = ResNet50(include_top=False, weights='imagenet',input_tensor=input_shape)\n","#model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9nGs7HX2cB8x"},"source":["\n","for layer in resModel.layers[:-2]:\n","  layer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8O-l-IEBc-uz"},"source":["import tensorflow as tf \n","model = K.models.Sequential()\n","model.add(resModel)\n","model.add(K.layers.Flatten())\n","model.add(K.layers.BatchNormalization())\n","model.add(K.layers.Dropout(0.7))\n","\n","model.add(K.layers.Dense(200, activation='softmax'))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mveaeog4eqCn"},"source":["model.compile(loss='categorical_crossentropy',\n","                  optimizer=K.optimizers.Adam(learning_rate=0.0001),\n","                  metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0-Pho42PAoV"},"source":["TRAIN_IMAGES.shape, TRAIN_LABELS.shape, TEST_IMAGES.shape, TEST_LABELS.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcARhlRGe0gK"},"source":["history = model.fit(TRAIN_IMAGES, TRAIN_LABELS, batch_size=32,  epochs=50, verbose=1,\n","                        validation_data=(TEST_IMAGES, TEST_LABELS),shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yv5PKIOJb_YM"},"source":["plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.title(\"Model Accuracy(Fine-Tunining)\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VImznndncFr2"},"source":["plt.plot(history.history['loss'],'r', label='Training Loss')\n","plt.plot(history.history['val_loss'],'c', label = 'Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(loc='upper right')\n","plt.title(\"Model Loss(Fine-Tunining)\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKVHLorR-vsj"},"source":["print('Training accuracy: ', np.around(history.history['accuracy'][49]*100, decimals=2),'%')\n","print('Validaiton accuracy: ', np.around(history.history['val_accuracy'][49]*100, decimals=2),'%')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_j5Vs3M-_2G"},"source":["prediction = model.evaluate(TEST_IMAGES,TEST_LABELS)\n","print(\"Testing Accuracy: \", np.around(prediction[1]*100, decimals=2))\n","print(\"Testing Loss: \", np.around(prediction[0],decimals=2))"],"execution_count":null,"outputs":[]}]}